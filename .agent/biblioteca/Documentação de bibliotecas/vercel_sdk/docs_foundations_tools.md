# https://sdk.vercel.ai/docs/foundations/tools

Copy markdown

[Tools](#tools)
===============

While [large language models (LLMs)](/docs/foundations/overview#large-language-models) have incredible generation capabilities,
they struggle with discrete tasks (e.g. mathematics) and interacting with the outside world (e.g. getting the weather).

Tools are actions that an LLM can invoke.
The results of these actions can be reported back to the LLM to be considered in the next response.

For example, when you ask an LLM for the "weather in London", and there is a weather tool available, it could call a tool
with London as the argument. The tool would then fetch the weather data and return it to the LLM. The LLM can then use this
information in its response.

[What is a tool?](#what-is-a-tool)
----------------------------------

A tool is an object that can be called by the model to perform a specific task.
You can use tools with [`generateText`](/docs/reference/ai-sdk-core/generate-text)
and [`streamText`](/docs/reference/ai-sdk-core/stream-text) by passing one or more tools to the `tools` parameter.

A tool consists of three properties:

* **`description`**: An optional description of the tool that can influence when the tool is picked.
* **`inputSchema`**: A [Zod schema](/docs/reference/ai-sdk-core/zod-schema) or a [JSON schema](/docs/reference/ai-sdk-core/json-schema) that defines the input required for the tool to run. The schema is consumed by the LLM, and also used to validate the LLM tool calls.
* **`execute`**: An optional async function that is called with the arguments from the tool call.

`streamUI` uses UI generator tools with a `generate` function that can return
React components.

If the LLM decides to use a tool, it will generate a tool call.
Tools with an `execute` function are run automatically when these calls are generated.
The output of the tool calls are returned using tool result objects.

You can automatically pass tool results back to the LLM
using [multi-step calls](/docs/ai-sdk-core/tools-and-tool-calling#multi-step-calls) with `streamText` and `generateText`.

[Types of Tools](#types-of-tools)
---------------------------------

The AI SDK supports three types of tools, each with different trade-offs:

### [Custom Tools](#custom-tools)

Custom tools are tools you define entirely yourself, including the description, input schema, and execute function. They are provider-agnostic and give you full control.

```
1

import { tool } from 'ai';



2

import { z } from 'zod';



3



4

const weatherTool = tool({



5

description: 'Get the weather in a location',



6

inputSchema: z.object({



7

location: z.string().describe('The location to get the weather for'),



8

}),



9

execute: async ({ location }) => {



10

// Your implementation



11

return { temperature: 72, conditions: 'sunny' };



12

},



13

});
```

**When to use**: When you need full control, want provider portability, or are implementing application-specific functionality.

### [Provider-Defined Tools](#provider-defined-tools)

Provider-defined tools are tools where the provider specifies the tool's `inputSchema` and `description`, but you provide the `execute` function. These are sometimes called "client tools" because execution happens on your side.

Examples include Anthropic's `bash` and `text_editor` tools. The model has been specifically trained to use these tools effectively, which can result in better performance for supported tasks.

```
1

import { anthropic } from '@ai-sdk/anthropic';



2

import { generateText } from 'ai';



3



4

const result = await generateText({



5

model: anthropic('claude-opus-4-5'),



6

tools: {



7

bash: anthropic.tools.bash_20250124({



8

execute: async ({ command }) => {



9

// Your implementation to run the command



10

return runCommand(command);



11

},



12

}),



13

},



14

prompt: 'List files in the current directory',



15

});
```

**When to use**: When the provider offers a tool the model is trained to use well, and you want better performance for that specific task.

### [Provider-Executed Tools](#provider-executed-tools)

Provider-executed tools are tools that run entirely on the provider's servers. You configure them, but the provider handles execution. These are sometimes called "server-side tools".

Examples include OpenAI's web search and Anthropic's code execution. These provide out-of-the-box functionality without requiring you to set up infrastructure.

```
1

import { openai } from '@ai-sdk/openai';



2

import { generateText } from 'ai';



3



4

const result = await generateText({



5

model: openai('gpt-5.2'),



6

tools: {



7

web_search: openai.tools.webSearch(),



8

},



9

prompt: 'What happened in the news today?',



10

});
```

**When to use**: When you want powerful functionality (like web search or sandboxed code execution) without managing the infrastructure yourself.

### [Comparison](#comparison)

| Aspect | Custom Tools | Provider-Defined Tools | Provider-Executed Tools |
| --- | --- | --- | --- |
| **Execution** | Your code | Your code | Provider's servers |
| **Schema** | You define | Provider defines | Provider defines |
| **Portability** | Works with any provider | Provider-specific | Provider-specific |
| **Model Training** | General tool use | Optimized for the tool | Optimized for the tool |
| **Setup** | You implement everything | You implement execute | Configuration only |

Provider-defined and provider-executed tools are documented in each provider's
page. See [Anthropic Provider](/providers/ai-sdk-providers/anthropic) and
[OpenAI Provider](/providers/ai-sdk-providers/openai) for examples.

[Schemas](#schemas)
-------------------

Schemas are used to define and validate the [tool input](/docs/ai-sdk-core/tools-and-tool-calling), tools outputs, and structured output generation.

The AI SDK supports the following schemas:

* [Zod](https://zod.dev/) v3 and v4 directly or via [`zodSchema()`](/docs/reference/ai-sdk-core/zod-schema)
* [Valibot](https://valibot.dev/) via [`valibotSchema()`](/docs/reference/ai-sdk-core/valibot-schema) from `@ai-sdk/valibot`
* [Standard JSON Schema](https://standardschema.dev/json-schema) compatible schemas
* Raw JSON schemas via [`jsonSchema()`](/docs/reference/ai-sdk-core/json-schema)

You can also use schemas for structured output generation with
[`generateText`](/docs/reference/ai-sdk-core/generate-text) and
[`streamText`](/docs/reference/ai-sdk-core/stream-text) using the `output`
setting.

[Tool Packages](#tool-packages)
-------------------------------

Given tools are JavaScript objects, they can be packaged and distributed through npm like any other library. This makes it easy to share reusable tools across projects and with the community.

### [Using Ready-Made Tool Packages](#using-ready-made-tool-packages)

Install a tool package and import the tools you need:

```
1

pnpm add some-tool-package
```

Then pass them directly to `generateText`, `streamText`, or your agent definition:

```
1

import { generateText, stepCountIs } from 'ai';



2

import { searchTool } from 'some-tool-package';



3



4

const { text } = await generateText({



5

model: 'anthropic/claude-haiku-4.5',



6

prompt: 'When was Vercel Ship AI?',



7

tools: {



8

webSearch: searchTool,



9

},



10

stopWhen: stepCountIs(10),



11

});
```

### [Publishing Your Own Tools](#publishing-your-own-tools)

You can publish your own tool packages to npm for others to use. Simply export your tool objects from your package:

```
1

// my-tools/index.ts



2

export const myTool = {



3

description: 'A helpful tool',



4

inputSchema: z.object({



5

query: z.string(),



6

}),



7

execute: async ({ query }) => {



8

// your tool logic



9

return result;



10

},



11

};
```

Anyone can then install and use your tools by importing them.

To get started, you can use the [AI SDK Tool Package Template](https://github.com/vercel-labs/ai-sdk-tool-as-package-template) which provides a ready-to-use starting point for publishing your own tools.

[Toolsets](#toolsets)
---------------------

When you work with tools, you typically need a mix of application-specific tools and general-purpose tools. The community has created various toolsets and resources to help you build and use tools.

### [Ready-to-Use Tool Packages](#ready-to-use-tool-packages)

These packages provide pre-built tools you can install and use immediately:

* **[@exalabs/ai-sdk](https://www.npmjs.com/package/@exalabs/ai-sdk)** - Web search tool that lets AI search the web and get real-time information.
* **[@parallel-web/ai-sdk-tools](https://www.npmjs.com/package/@parallel-web/ai-sdk-tools)** - Web search and extract tools powered by Parallel Web API for real-time information and content extraction.
* **[@perplexity-ai/ai-sdk](https://www.npmjs.com/package/@perplexity-ai/ai-sdk)** - Search the web with real-time results and advanced filtering powered by Perplexity's Search API.
* **[@tavily/ai-sdk](https://www.npmjs.com/package/@tavily/ai-sdk)** - Search, extract, crawl, and map tools for enterprise-grade agents to explore the web in real-time.
* **[Stripe agent tools](https://docs.stripe.com/agents?framework=vercel)** - Tools for interacting with Stripe.
* **[StackOne ToolSet](https://docs.stackone.com/agents/typescript/frameworks/vercel-ai-sdk)** - Agentic integrations for hundreds of [enterprise SaaS](https://www.stackone.com/integrations) platforms.
* **[agentic](https://docs.agentic.so/marketplace/ts-sdks/ai-sdk)** - A collection of 20+ tools that connect to external APIs such as [Exa](https://exa.ai/) or [E2B](https://e2b.dev/).
* **[Amazon Bedrock AgentCore](https://github.com/aws/bedrock-agentcore-sdk-typescript)** - Fully managed AI agent services including [**Browser**](https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/built-in-tools.html) (a fast and secure cloud-based browser runtime to enable agents to interact with web applications, fill forms, navigate websites, and extract information) and [**Code Interpreter**](https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/built-in-tools.html) (an isolated sandbox environment for agents to execute code in Python, JavaScript, and TypeScript, enhancing accuracy and expanding ability to solve complex end-to-end tasks).
* **[@airweave/vercel-ai-sdk](https://www.npmjs.com/package/@airweave/vercel-ai-sdk)** - Unified semantic search across 35+ data sources (Notion, Slack, Google Drive, databases, and more) for AI agents.
* **[Composio](https://docs.composio.dev/providers/vercel)** - 250+ tools like GitHub, Gmail, Salesforce and [more](https://composio.dev/tools).
* **[JigsawStack](http://www.jigsawstack.com/docs/integration/vercel)** - Over 30+ small custom fine-tuned models available for specific uses.
* **[AI Tools Registry](https://ai-tools-registry.vercel.app)** - A Shadcn-compatible tool definitions and components registry for the AI SDK.
* **[Toolhouse](https://docs.toolhouse.ai/toolhouse/toolhouse-sdk/using-vercel-ai)** - AI function-calling in 3 lines of code for over 25 different actions.
* **[bash-tool](https://www.npmjs.com/package/bash-tool)** - Provides `bash`, `readFile`, and `writeFile` tools for AI agents. Supports [@vercel/sandbox](https://vercel.com/docs/vercel-sandbox) for full VM isolation.

### [MCP Tools](#mcp-tools)

These are pre-built tools available as MCP servers:

* **[Smithery](https://smithery.ai/docs/integrations/vercel_ai_sdk)** - An open marketplace of 6,000+ MCPs, including [Browserbase](https://browserbase.com/) and [Exa](https://exa.ai/).
* **[Pipedream](https://pipedream.com/docs/connect/mcp/ai-frameworks/vercel-ai-sdk)** - Developer toolkit that lets you easily add 3,000+ integrations to your app or AI agent.
* **[Apify](https://docs.apify.com/platform/integrations/vercel-ai-sdk)** - Apify provides a [marketplace](https://apify.com/store) of thousands of tools for web scraping, data extraction, and browser automation.

### [Tool Building Tutorials](#tool-building-tutorials)

These tutorials and guides help you build your own tools that integrate with specific services:

* **[browserbase](https://docs.browserbase.com/integrations/vercel/introduction#vercel-ai-integration)** - Tutorial for building browser tools that run a headless browser.
* **[browserless](https://docs.browserless.io/ai-integrations/vercel-ai-sdk)** - Guide for integrating browser automation (self-hosted or cloud-based).
* **[AI Tool Maker](https://github.com/nihaocami/ai-tool-maker)** - A CLI utility to generate AI SDK tools from OpenAPI specs.
* **[Interlify](https://www.interlify.com/docs/integrate-with-vercel-ai)** - Guide for converting APIs into tools.
* **[DeepAgent](https://deepagent.amardeep.space/docs/vercel-ai-sdk)** - A suite of 50+ AI tools and integrations, seamlessly connecting with APIs like Tavily, E2B, Airtable and [more](https://deepagent.amardeep.space/docs).

Do you have open source tools or tool libraries that are compatible with the
AI SDK? Please [file a pull request](https://github.com/vercel/ai/pulls) to
add them to this list.

[Learn more](#learn-more)
-------------------------

The AI SDK Core [Tool Calling](/docs/ai-sdk-core/tools-and-tool-calling)
and [Agents](/docs/foundations/agents) documentation has more information about tools and tool calling.